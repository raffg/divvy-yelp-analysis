{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Divvy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and concat the Divvy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy1 = pd.read_csv('data/Divvy_Trips_2017_Q1Q2/Divvy_Trips_2017_Q1.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy2 = pd.read_csv('data/Divvy_Trips_2017_Q1Q2/Divvy_Trips_2017_Q2.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy3 = pd.read_csv('data/Divvy_Trips_2017_Q3Q4/Divvy_Trips_2017_Q3.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy4 = pd.read_csv('data/Divvy_Trips_2017_Q3Q4/Divvy_Trips_2017_Q4.csv', parse_dates=['start_time', 'end_time'])\n",
    "\n",
    "# divvy = pd.concat([divvy1, divvy2, divvy3, divvy4], ignore_index=True)\n",
    "\n",
    "# divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = set(list(divvy['from_station_name'].unique()) + list(divvy['to_station_name'].unique()))\n",
    "station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Divvy station info for GPS coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stations.json') as json_data:\n",
    "    station_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data['stationBeanList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [station['stationName'] for station in station_data['stationBeanList']]\n",
    "latitude = [station['latitude'] for station in station_data['stationBeanList']]\n",
    "longitude = [station['longitude'] for station in station_data['stationBeanList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = []\n",
    "for station in station_list:\n",
    "    if station not in stations:\n",
    "        unknown.append(station)\n",
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_gps = pd.DataFrame({'station_name': stations, 'latitude': latitude, 'longitude': longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps_lookup(location):\n",
    "    match = (station_gps['station_name'] == location)\n",
    "    coord = station_gps['latitude'][match]\n",
    "    if len(coord) > 0:\n",
    "        return pd.Series([coord.values[0], station_gps['longitude'][match].values[0]])\n",
    "    else:\n",
    "        return pd.Series([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['from_station_latitude', 'from_station_longitude']] = divvy['from_station_name'].apply(gps_lookup)\n",
    "divvy[['to_station_latitude', 'to_station_longitude']] = divvy['to_station_name'].apply(gps_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Top 5 stations with the most starts (showing # of starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_starts = divvy.groupby(['from_station_name'])['from_station_name'].count().sort_values(ascending=False)\n",
    "station_starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = station_starts.head(5).plot(kind='bar', figsize=(15, 10), title='Top 5 Stations with Most Starts')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .15, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trip duration by user type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration = divvy.groupby(['usertype'])['tripduration'].mean().sort_values(ascending=False)\n",
    "trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10), showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Most popular trips based on start station and stop station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_stations'] = divvy['from_station_name'] + ' TO ' + divvy['to_station_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stations = divvy.groupby(['trip_stations'])['trip_stations'].count().sort_values(ascending=False)\n",
    "trip_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = trip_stations.head(10).plot(kind='bar', figsize=(15, 10), title='Top 10 Most Popular Trips')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .05, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe of paths for Tableau chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dict = {'path': list(trip_stations.index), 'frequency': list(trip_stations.values)}\n",
    "trip_dict['origin'] = [x.split(' TO ')[0] for x in trip_dict['path']]\n",
    "trip_dict['destination'] = [x.split(' TO ')[1] for x in trip_dict['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "trips = defaultdict(list)\n",
    "\n",
    "for idx in range(len(trip_dict['path'])):\n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['frequency'].append(trip_dict['frequency'][idx])\n",
    "    trips['origin-destination'].append('origin')\n",
    "    trips['station'].append(trip_dict['origin'][idx])\n",
    "    \n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['frequency'].append(trip_dict['frequency'][idx])\n",
    "    trips['origin-destination'].append('destination')\n",
    "    trips['station'].append(trip_dict['destination'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gps = (divvy[divvy['from_station_name'].duplicated()]\n",
    "                [['from_station_name', 'from_station_latitude', 'from_station_longitude']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.DataFrame(trips).merge(stations_gps.drop_duplicates(subset=['from_station_name']),\n",
    "                                     how='left',\n",
    "                                     left_on='station',\n",
    "                                     right_on='from_station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.drop(['from_station_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv('data/trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Rider performance by Gender and Age based on avg trip distance (station to station), median speed (distance traveled / trip duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply geodesic distance by 1.25. Routes follow roads but the calculated route is direct (geodesic). A route straight down a road would be the same as the direct route; a route diagnoal to roads would be multiplied by 1.414 (thanks, Pythagoras!); assuming routes are evenly split between diagonal and direct, with some wiggle room, I'm splitting the difference at 1.25.\n",
    "\n",
    "I looked at using the Google Maps api to calculate the actual, along-the-road distance, but they've removed the free api key option. I also looked at Bing Maps, but it's rate limited and I have more than 98,000 routes in this dataset (and once I saw how big that number was, I realized that using api calls would take more than a few days!). So I opted for this *x1.25* method which is less accurate but far quicker and cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "def find_distance(row):\n",
    "    if (not isnan(row['from_station_latitude']) and\n",
    "        not isnan(row['from_station_longitude']) and\n",
    "        not isnan(row['to_station_latitude']) and\n",
    "        not isnan(row['to_station_longitude'])):\n",
    "        return (1.25 * (geopy.distance.distance((row['from_station_latitude'], row['from_station_longitude']),\n",
    "                                                (row['to_station_latitude'], row['to_station_longitude'])).m))\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "def find_distance(row):\n",
    "    if (not isnan(row['from_station_latitude']) and\n",
    "        not isnan(row['from_station_longitude']) and\n",
    "        not isnan(row['to_station_latitude']) and\n",
    "        not isnan(row['to_station_longitude'])):\n",
    "        distance = (1.25 * (geopy.distance.distance((row['from_station_latitude'], row['from_station_longitude']),\n",
    "                                                (row['to_station_latitude'], row['to_station_longitude'])).m))\n",
    "        print(distance)\n",
    "        return distance\n",
    "    else:\n",
    "        print(np.nan)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_distance'] = divvy.apply(find_distance, axis=1)\n",
    "divvy['speed'] = divvy['trip_distance'] / divvy['tripduration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json('data/yelp_dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "\n",
    "checkin = pd.read_json('data/yelp_dataset/yelp_academic_dataset_checkin.json', lines=True)\n",
    "\n",
    "max_records = 1e5\n",
    "df = pd.read_json('data/yelp_dataset/yelp_academic_dataset_review.json', lines=True, chunksize=max_records)\n",
    "review = pd.DataFrame() # Initialize the dataframe\n",
    "try:\n",
    "    for df_chunk in df:\n",
    "        review = pd.concat([review, df_chunk])\n",
    "except ValueError:\n",
    "    print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin['checkins'] = checkin['time'].apply(lambda x : sum(x.values()))\n",
    "yelp = business.merge(checkin, on='business_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.to_csv('data/yelp_business.csv', index=False)\n",
    "checkin.to_csv('data/yelp_checkin.csv', index=False)\n",
    "review.to_csv('data/yelp_review.csv', index=False)\n",
    "yelp.to_csv('data/yelp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review['date'] = pd.to_datetime(review['date'])\n",
    "review[review['date'].dt.year == 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the top 10 and bottom 10 restaurants in Illinois having most and least checkins respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['checkins'] = yelp['time'].apply(lambda x : sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin['checkins'] = checkin['time'].apply(lambda x : sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'].isnull()) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 1) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 2) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 3) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = yelp[(yelp['state'] == 'IL') &\n",
    "             (yelp['categories'].str.contains('Restaurants') &\n",
    "              (yelp['is_open'] == 1))\n",
    "            ].sort_values('checkins', ascending=False).head(10)\n",
    "\n",
    "bottom10 = yelp[(yelp['state'] == 'IL') &\n",
    "                (yelp['categories'].str.contains('Restaurants') &\n",
    "                (yelp['is_open'] == 1))\n",
    "               ].sort_values('checkins', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bottom10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.to_csv('data/yelp_top10_checkins.csv', index=False)\n",
    "bottom10.to_csv('data/yelp_bottom10_checkins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_names = top10['name'].tolist()\n",
    "top10_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_names = bottom10['name'].tolist()\n",
    "bottom10_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the top 10 and bottom 10 restaurants calculated in step 6, calculate the average star rating and average sentiment score of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bottom = top10['business_id'].tolist() + bottom10['business_id'].tolist()\n",
    "top_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = review[review['business_id'].isin(top_bottom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_vader_scores(text):\n",
    "    '''\n",
    "    Takes a string of text and outputs four values for Vader's negative,\n",
    "    neutral, positive, and compound (normalized) sentiment scores\n",
    "    INPUT: a string\n",
    "    OUTPUT: a dictionary of four sentiment scores\n",
    "    '''\n",
    "\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    return analyser.polarity_scores(text)\n",
    "\n",
    "\n",
    "def apply_vader(df, column):\n",
    "    '''\n",
    "    Takes a DataFrame with a specified column of text and adds four new columns\n",
    "    to the DataFrame, corresponding to the Vader sentiment scores\n",
    "    INPUT: DataFrame, string\n",
    "    OUTPUT: the original DataFrame with four additional columns\n",
    "    '''\n",
    "\n",
    "    sentiment = pd.DataFrame(df[column].apply(get_vader_scores))\n",
    "    unpacked = pd.DataFrame([d for idx, d in sentiment['text'].iteritems()],\n",
    "                            index=sentiment.index)\n",
    "    unpacked['compound'] += 1\n",
    "    columns = {'neu': 'v_neutral', 'pos': 'v_positive', 'neg': 'v_negative'}\n",
    "    unpacked.rename(columns=columns, inplace=True)\n",
    "    return pd.concat([df, unpacked], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = apply_vader(sentiment, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_sentiment = {}\n",
    "for biz_id in top10['business_id'].tolist():\n",
    "    top10_sentiment[yelp.loc[yelp['business_id'] == biz_id, 'name'].iloc[0]] = sentiment[sentiment['business_id'] == biz_id].groupby(['business_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores = pd.DataFrame()\n",
    "for restaurant in top10_sentiment:\n",
    "    top10_scores = top10_scores.append(pd.DataFrame(top10_sentiment[restaurant]))\n",
    "top10_scores.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores['name'] = top10_scores['business_id'].apply(lambda business_id: yelp['name']\n",
    "                                                         [(yelp['business_id'] == business_id)].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_sentiment = {}\n",
    "for biz_id in bottom10['business_id'].tolist():\n",
    "    bottom10_sentiment[yelp.loc[yelp['business_id'] == biz_id, 'name'].iloc[0]] = sentiment[sentiment['business_id'] == biz_id].groupby(['business_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores = pd.DataFrame()\n",
    "for restaurant in bottom10_sentiment:\n",
    "    bottom10_scores = bottom10_scores.append(pd.DataFrame(bottom10_sentiment[restaurant]))\n",
    "bottom10_scores.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores['name'] = bottom10_scores['business_id'].apply(lambda business_id: yelp['name']\n",
    "                                                               [(yelp['business_id'] == business_id)].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores.to_csv('data/yelp_top_scores.csv', index=False)\n",
    "bottom10_scores.to_csv('data/yelp_bottom_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 10 Cuisine types (Mexican, American, Thai, etc) based on the number of restaurants and number of check ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = yelp[yelp['categories'].str.contains('Restaurants', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "restaurants['categories'] = restaurants['categories'].apply(lambda x: x.split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = restaurants.join(pd.get_dummies(pd.DataFrame(restaurants['categories'].tolist()).stack()).astype(int).sum(level=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [item for item in restaurants.columns.tolist() if item not in yelp.columns.tolist()]\n",
    "columns.remove('Restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_restaurants = restaurants[columns].sum(numeric_only=True).sort_values(ascending=False)\n",
    "num_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_dict ={}\n",
    "for item in columns:\n",
    "    cnt = restaurants[restaurants[item] == 1].groupby([item])['checkins'].sum()\n",
    "    if cnt.empty:\n",
    "        checkin_dict[item] = 0\n",
    "    else:\n",
    "        checkin_dict[item] = restaurants[restaurants[item] == 1].groupby([item])['checkins'].sum().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_dict = pd.Series(checkin_dict).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in checkin_dict.keys():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(checkin_dict).to_csv('data/yelp_cuisine_checkin.csv')\n",
    "pd.DataFrame(num_restaurants).to_csv('data/yelp_cuisine_restaurants.csv',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most popular keywords or adjectives that reviewers use for the above list of cuisines (calculated in step 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_list = ['American (Traditional)', 'Mexican', 'Chinese', 'Italian', 'American (New)',\n",
    "               'Japanese', 'Thai', 'Mediterranean', 'Asian Fusion', 'Indian', 'Korean',\n",
    "                'Greek', 'Mddle Eastern', 'Vietnamese', 'French', 'Tex-Mex', 'Caribbean']\n",
    "cuisines = pd.DataFrame()\n",
    "for cuisine in cuisine_list:\n",
    "    businesses = yelp[yelp['categories'].str.contains(cuisine, na=False)]['business_id'].tolist()\n",
    "    temp = review[review['business_id'].isin(businesses)]\n",
    "    temp['cuisine'] = cuisine\n",
    "    cuisines = pd.concat([cuisines, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines['date'] = pd.to_datetime(cuisines['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines_2017 = cuisines[cuisines['date'].dt.year == 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = cuisines_2017.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_docs = {}\n",
    "for cuisine in cuisine_list:\n",
    "    cuisine_docs[cuisine] = cuisines[cuisines['cuisine'] == cuisine]['text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "for cuisine in cuisine_list:\n",
    "    doc = nlp(cuisine_docs[cuisine])\n",
    "    # all tokens that arent stop words or punctuations\n",
    "    words = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "    # noun tokens that arent stop words or punctuations\n",
    "    nouns = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "\n",
    "    # five most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(5)\n",
    "\n",
    "    # five most common noun tokens\n",
    "    noun_freq = Counter(nouns)\n",
    "    common_nouns = noun_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "nlp.max_length=3000000\n",
    "doc = nlp(cuisine_docs['Mexican'])\n",
    "# all tokens that arent stop words or punctuations\n",
    "words = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "# noun tokens that arent stop words or punctuations\n",
    "nouns = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "# five most common noun tokens\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cuisine in cuisine_list:\n",
    "    print(cuisine, len(cuisine_docs[cuisine]) / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy = pd.read_csv('data/chicago-divvy-bicycle-sharing-data/data_raw.csv', parse_dates=['starttime', 'stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy = divvy[divvy['starttime'].dt.year == 2017].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy.to_csv('data/divvy_2017_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Top 5 stations with the most starts (showing # of starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_starts = divvy.groupby(['from_station_name'])['from_station_name'].count().sort_values(ascending=False)\n",
    "station_starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = station_starts.head(5).plot(kind='bar', figsize=(15, 10), title='Top 5 Stations with Most Starts')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .15, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_coord = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = Basemap(width=10000000,height=6000000,projection='lcc',\n",
    "            resolution=None,lat_1=45.,lat_2=55,lat_0=50,lon_0=-107.)\n",
    "plt.figure(figsize=(19,20))\n",
    "map.bluemarble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in station_starts[5]:\n",
    "        loc = geolocator.geocode(city)\n",
    "        if not loc:\n",
    "            print(\"Could not locate {}\".format(city))\n",
    "            continue\n",
    "        x, y = map(loc.longitude, loc.latitude)\n",
    "        map.plot(x,y,marker='o',color='Red',markersize=int(math.sqrt(count))*scale)\n",
    "        plt.annotate(city, xy = (x,y), xytext=(-20,20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trip duration by user type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration = divvy.groupby(['usertype'])['tripduration'].mean().sort_values(ascending=False)\n",
    "trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10), showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Most popular trips based on start station and stop station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_stations'] = divvy['from_station_name'] + ' TO ' + divvy['to_station_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stations = divvy.groupby(['trip_stations'])['trip_stations'].count().sort_values(ascending=False)\n",
    "trip_stations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = trip_stations.head(10).plot(kind='bar', figsize=(15, 10), title='Top 10 Most Popular Trips')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .05, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dict = {'path': list(trip_stations.index), 'frequency': list(trip_stations.values)}\n",
    "trip_dict['origin'] = [x.split(' TO ')[0] for x in trip_dict['path']]\n",
    "trip_dict['destination'] = [x.split(' TO ')[1] for x in trip_dict['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "trips = defaultdict(list)\n",
    "\n",
    "for idx in range(len(trip_dict['path'])):\n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['origin-destination'].append('origin')\n",
    "    trips['station'].append(trip_dict['origin'][idx])\n",
    "    \n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['origin-destination'].append('destination')\n",
    "    trips['station'].append(trip_dict['destination'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gps = (divvy[divvy['from_station_name'].duplicated()]\n",
    "                [['from_station_name', 'latitude_start', 'longitude_start']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.DataFrame(trips).merge(stations_gps, how='left', left_on='station', right_on='from_station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv('data/trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Rider performance by Gender and Age based on avg trip distance (station to station), median speed (distance traveled / trip duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply geodesic distance by 1.25. Routes follow roads but the calculated route is direct (geodesic). A route straight down a road would be the same as the direct route; a route diagnoal to roads would be multiplied by 1.414 (thanks, Pythagoras!); assuming routes are evenly split between diagonal and direct, with some wiggle room, I'm splitting the difference at 1.25.\n",
    "\n",
    "I looked at using the Google Maps api to calculate the actual, along-the-road distance, but they've removed the free api key option. I also looked at Bing Maps, but it's rate limited and I have more than 98,000 routes in this dataset (and once I saw how big that number was, I realized that using api calls would take more than a few days!). So I opted for this *x1.25* method which is less accurate but far quicker and cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(row):\n",
    "    return (1.25 * (geopy.distance.distance((row['latitude_start'], row['longitude_start']),\n",
    "                                            (row['latitude_end'], row['longitude_end'])).m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_distance'] = divvy.apply(find_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['speed'] = divvy['trip_distance'] / divvy['tripduration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['starttime', 'stoptime', 'tripduration', 'latitude_start', 'longitude_start', 'latitude_end', 'longitude_end', 'trip_distance', 'speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
