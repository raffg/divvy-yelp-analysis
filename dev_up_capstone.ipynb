{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Divvy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and concat the Divvy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy1 = pd.read_csv('data/Divvy_Trips_2017_Q1Q2/Divvy_Trips_2017_Q1.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy2 = pd.read_csv('data/Divvy_Trips_2017_Q1Q2/Divvy_Trips_2017_Q2.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy3 = pd.read_csv('data/Divvy_Trips_2017_Q3Q4/Divvy_Trips_2017_Q3.csv', parse_dates=['start_time', 'end_time'])\n",
    "# divvy4 = pd.read_csv('data/Divvy_Trips_2017_Q3Q4/Divvy_Trips_2017_Q4.csv', parse_dates=['start_time', 'end_time'])\n",
    "\n",
    "# divvy = pd.concat([divvy1, divvy2, divvy3, divvy4], ignore_index=True)\n",
    "\n",
    "# divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_list = set(list(divvy['from_station_name'].unique()) + list(divvy['to_station_name'].unique()))\n",
    "station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(station_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Divvy station info for GPS coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stations.json') as json_data:\n",
    "    station_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data['stationBeanList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [station['stationName'] for station in station_data['stationBeanList']]\n",
    "latitude = [station['latitude'] for station in station_data['stationBeanList']]\n",
    "longitude = [station['longitude'] for station in station_data['stationBeanList']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = []\n",
    "for station in station_list:\n",
    "    if station not in stations:\n",
    "        unknown.append(station)\n",
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_gps = pd.DataFrame({'station_name': stations, 'latitude': latitude, 'longitude': longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gps_lookup(location):\n",
    "    match = (station_gps['station_name'] == location)\n",
    "    coord = station_gps['latitude'][match]\n",
    "    if len(coord) > 0:\n",
    "        return pd.Series([coord.values[0], station_gps['longitude'][match].values[0]])\n",
    "    else:\n",
    "        return pd.Series([np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['from_station_latitude', 'from_station_longitude']] = divvy['from_station_name'].apply(gps_lookup)\n",
    "divvy[['to_station_latitude', 'to_station_longitude']] = divvy['to_station_name'].apply(gps_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Top 5 stations with the most starts (showing # of starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_starts = divvy.groupby(['from_station_name'])['from_station_name'].count().sort_values(ascending=False)\n",
    "station_starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = station_starts.head(5).plot(kind='bar', figsize=(15, 10), title='Top 5 Stations with Most Starts')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .15, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trip duration by user type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration = divvy.groupby(['usertype'])['tripduration'].mean().sort_values(ascending=False)\n",
    "trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10), showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Most popular trips based on start station and stop station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_stations'] = divvy['from_station_name'] + ' TO ' + divvy['to_station_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stations = divvy.groupby(['trip_stations'])['trip_stations'].count().sort_values(ascending=False)\n",
    "trip_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = trip_stations.head(10).plot(kind='bar', figsize=(15, 10), title='Top 10 Most Popular Trips')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .05, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe of paths for Tableau chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dict = {'path': list(trip_stations.index), 'frequency': list(trip_stations.values)}\n",
    "trip_dict['origin'] = [x.split(' TO ')[0] for x in trip_dict['path']]\n",
    "trip_dict['destination'] = [x.split(' TO ')[1] for x in trip_dict['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "trips = defaultdict(list)\n",
    "\n",
    "for idx in range(len(trip_dict['path'])):\n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['frequency'].append(trip_dict['frequency'][idx])\n",
    "    trips['origin-destination'].append('origin')\n",
    "    trips['station'].append(trip_dict['origin'][idx])\n",
    "    \n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['frequency'].append(trip_dict['frequency'][idx])\n",
    "    trips['origin-destination'].append('destination')\n",
    "    trips['station'].append(trip_dict['destination'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gps = (divvy[divvy['from_station_name'].duplicated()]\n",
    "                [['from_station_name', 'from_station_latitude', 'from_station_longitude']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.DataFrame(trips).merge(stations_gps.drop_duplicates(subset=['from_station_name']),\n",
    "                                     how='left',\n",
    "                                     left_on='station',\n",
    "                                     right_on='from_station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.drop(['from_station_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv('data/divvy_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Rider performance by Gender and Age based on avg trip distance (station to station), median speed (distance traveled / trip duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply geodesic distance by 1.25. Routes follow roads but the calculated route is direct (geodesic). A route straight down a road would be the same as the direct route; a route diagnoal to roads would be multiplied by 1.414 (thanks, Pythagoras!); assuming routes are evenly split between diagonal and direct, with some wiggle room, I'm splitting the difference at 1.25.\n",
    "\n",
    "I looked at using the Google Maps api to calculate the actual, along-the-road distance, but they've removed the free api key option. I also looked at Bing Maps, but it's rate limited and I have more than 98,000 routes in this dataset (and once I saw how big that number was, I realized that using api calls would take more than a few days!). So I opted for this *x1.25* method which is less accurate but far quicker and cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "def find_distance(row):\n",
    "    if (not isnan(row['from_station_latitude']) and\n",
    "        not isnan(row['from_station_longitude']) and\n",
    "        not isnan(row['to_station_latitude']) and\n",
    "        not isnan(row['to_station_longitude'])):\n",
    "        return (1.25 * (geopy.distance.distance((row['from_station_latitude'], row['from_station_longitude']),\n",
    "                                                (row['to_station_latitude'], row['to_station_longitude'])).m))\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "def find_distance(row):\n",
    "    if (not isnan(row['from_station_latitude']) and\n",
    "        not isnan(row['from_station_longitude']) and\n",
    "        not isnan(row['to_station_latitude']) and\n",
    "        not isnan(row['to_station_longitude'])):\n",
    "        distance = (1.25 * (geopy.distance.distance((row['from_station_latitude'], row['from_station_longitude']),\n",
    "                                                (row['to_station_latitude'], row['to_station_longitude'])).m))\n",
    "        print(distance)\n",
    "        return distance\n",
    "    else:\n",
    "        print(np.nan)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_distance'] = divvy.apply(find_distance, axis=1)\n",
    "divvy['speed'] = divvy['trip_distance'] / divvy['tripduration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.to_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = pd.read_json('data/yelp_dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "\n",
    "checkin = pd.read_json('data/yelp_dataset/yelp_academic_dataset_checkin.json', lines=True)\n",
    "\n",
    "max_records = 1e5\n",
    "df = pd.read_json('data/yelp_dataset/yelp_academic_dataset_review.json', lines=True, chunksize=max_records)\n",
    "review = pd.DataFrame() # Initialize the dataframe\n",
    "try:\n",
    "    for df_chunk in df:\n",
    "        review = pd.concat([review, df_chunk])\n",
    "except ValueError:\n",
    "    print ('\\nSome messages in the file cannot be parsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin['checkins'] = checkin['time'].apply(lambda x : sum(x.values()))\n",
    "yelp = business.merge(checkin, on='business_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.to_csv('data/yelp_business.csv', index=False)\n",
    "checkin.to_csv('data/yelp_checkin.csv', index=False)\n",
    "review.to_csv('data/yelp_review.csv', index=False)\n",
    "yelp.to_csv('data/yelp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review['date'] = pd.to_datetime(review['date'])\n",
    "review = review[review['date'].dt.year == 2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the top 10 and bottom 10 restaurants in Illinois having most and least checkins respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'].isnull()) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 1) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 2) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yelp[(yelp['state'] == 'IL') &\n",
    "         (yelp['categories'].str.contains('Restaurants')) &\n",
    "         (yelp['checkins'] == 3) &\n",
    "         (yelp['is_open'] == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = yelp[(yelp['state'] == 'IL') &\n",
    "             (yelp['categories'].str.contains('Restaurants') &\n",
    "              (yelp['is_open'] == 1))\n",
    "            ].sort_values('checkins', ascending=False).head(10)\n",
    "\n",
    "bottom10 = yelp[(yelp['state'] == 'IL') &\n",
    "                (yelp['categories'].str.contains('Restaurants') &\n",
    "                (yelp['is_open'] == 1))\n",
    "               ].sort_values('checkins', ascending=False).tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bottom10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.to_csv('data/yelp_top10_checkins.csv', index=False)\n",
    "bottom10.to_csv('data/yelp_bottom10_checkins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sakanaya',\n",
       " 'Black Dog Smoke & Ale House',\n",
       " 'DESTIHL Restaurant & Brew Works',\n",
       " 'Seven Saints',\n",
       " 'Golden Harbor Authentic Chinese Cuisine',\n",
       " 'Maize Mexican Grill',\n",
       " 'Meijer',\n",
       " 'Cafe Kopi',\n",
       " 'Courier Cafe',\n",
       " 'Big Grove Tavern']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_names = top10['name'].tolist()\n",
    "top10_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monicals Pizza',\n",
       " 'Subway',\n",
       " \"McDonald's\",\n",
       " 'The Spice Box',\n",
       " 'Subway',\n",
       " 'Taco Bell',\n",
       " 'Subway',\n",
       " 'Asian Noodle and Sushi',\n",
       " 'Red Cape Hot Pot',\n",
       " \"McDonald's\",\n",
       " 'Main Street Belly Deli',\n",
       " 'Subway',\n",
       " 'Little Caesars Pizza',\n",
       " 'Casa Real',\n",
       " 'Tasty Fish Chicken & Grill',\n",
       " \"J & J's Burgers & Beer\",\n",
       " 'Casa Del Mar',\n",
       " 'Dairy Queen',\n",
       " 'Nanjing Bistro',\n",
       " \"Bergie's - The Occasional Place\",\n",
       " 'Sushi San',\n",
       " \"Papa John's Pizza\",\n",
       " \"Domino's Pizza\",\n",
       " 'Golden Kitchen',\n",
       " 'The Wild Hare',\n",
       " 'Stango Cuisine',\n",
       " \"Tortica's Grill\",\n",
       " 'Manzellas Italian Restaurant',\n",
       " \"Jimmy John's\",\n",
       " \"Domino's Pizza\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom10_names = bottom10['name'].tolist()\n",
    "bottom10_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the top 10 and bottom 10 restaurants calculated in step 6, calculate the average star rating and average sentiment score of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-zEpEmDfFQL-ph0N3BDlXA',\n",
       " '9MnbQg7kfb_WgxoV0hXKSQ',\n",
       " '-fiUXzkxRfbHY9TKWwuptw',\n",
       " 'L2c-qKZWumCmOCR-dqBLrg',\n",
       " 't_yiQnxUDdPPCN2z4QyezA',\n",
       " 'VIJ2KiDKhUVhhpNylEIfog',\n",
       " 'XbHxWOciYlBhJOjKRQbo9g',\n",
       " 'e0prCZXtHGQIKeQ_wTW3uw',\n",
       " 'o13eH93qmWVNFZogkjhd9w',\n",
       " 'dn9lwYUxmhs_mLKPu7L25Q',\n",
       " 'DLhAuWok29OU8VR-DBxP7A',\n",
       " 'RDr-19q3FSDLezc_kJK88w',\n",
       " 'n3AHTASqE5QCfuq0AQpT5Q',\n",
       " 'fsBAaw7xwHWB78HRSWwQEQ',\n",
       " 'ZjJzuxjpOTAPWTFbaX06ew',\n",
       " 'hH7qhup_bGKr9r27RpHJPw',\n",
       " 'zaoGcD35rSuuAwc7DLiSMw',\n",
       " 'hz18cj0wMLa5X9GVW-Un9A',\n",
       " 'ZvSy8yaly9Aeh64Qm4Dsfw',\n",
       " 'AZRREnqWvjnL4VqSovXHcA',\n",
       " 'IFlSq9YWXHZyLnuh0EffKQ',\n",
       " 'N9osJe0lQOdnd3xLUkJVMw',\n",
       " 'ks6JgGsz7phkGEVh9hoHkg',\n",
       " 'AW_d5hMf7sI6yHrz4Ujv8w',\n",
       " '62Ibju8UmUZtPIBLDS_nUw',\n",
       " 'KkpX5EdixY0C5gUq8BcmCA',\n",
       " 'LvPbZ_5odnjE_oj5BNHivQ',\n",
       " 'sDfN5qJlmvrwTfwEPBsxSg',\n",
       " 'Hc5NrzzzL8RAnbcrIAvZug',\n",
       " 'VhgHIT3Krb278n5RcPXVsg',\n",
       " 'IYASJOu_TXz8PpPbt-Clbg',\n",
       " '83_gVj7cnJd0-J5ZoYN9qA',\n",
       " '3XUH9aFxt4vU9Pzi5aBtow',\n",
       " 'W7KtVjq4R_5F5EwbCBENQw',\n",
       " '21UO0mP1EgEDZyFUFFI9Mg',\n",
       " '-yZ78Hd2DKDqvxJKbCyELg',\n",
       " 'Pq_dAtQ4i1wkyWsEiFYrEA',\n",
       " 'gWZOW4-8N5dLixQAlp8iRg',\n",
       " 'tkbRjBlZm7ngEVSu22n0vg',\n",
       " 'hjo4IYguwprIJ16A8lV75A']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_bottom = top10['business_id'].tolist() + bottom10['business_id'].tolist()\n",
    "top_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = review[review['business_id'].isin(top_bottom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_vader_scores(text):\n",
    "    '''\n",
    "    Takes a string of text and outputs four values for Vader's negative,\n",
    "    neutral, positive, and compound (normalized) sentiment scores\n",
    "    INPUT: a string\n",
    "    OUTPUT: a dictionary of four sentiment scores\n",
    "    '''\n",
    "\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    return analyser.polarity_scores(text)\n",
    "\n",
    "\n",
    "def apply_vader(df, column):\n",
    "    '''\n",
    "    Takes a DataFrame with a specified column of text and adds four new columns\n",
    "    to the DataFrame, corresponding to the Vader sentiment scores\n",
    "    INPUT: DataFrame, string\n",
    "    OUTPUT: the original DataFrame with four additional columns\n",
    "    '''\n",
    "\n",
    "    sentiment = pd.DataFrame(df[column].apply(get_vader_scores))\n",
    "    unpacked = pd.DataFrame([d for idx, d in sentiment['text'].iteritems()],\n",
    "                            index=sentiment.index)\n",
    "    unpacked['compound'] += 1\n",
    "    columns = {'neu': 'v_neutral', 'pos': 'v_positive', 'neg': 'v_negative'}\n",
    "    unpacked.rename(columns=columns, inplace=True)\n",
    "    return pd.concat([df, unpacked], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = apply_vader(sentiment, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_sentiment = {}\n",
    "for biz_id in top10['business_id'].tolist():\n",
    "    top10_sentiment[yelp.loc[yelp['business_id'] == biz_id, 'name'].iloc[0]] = sentiment[sentiment['business_id'] == biz_id].groupby(['business_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores = pd.DataFrame()\n",
    "for restaurant in top10_sentiment:\n",
    "    top10_scores = top10_scores.append(pd.DataFrame(top10_sentiment[restaurant]))\n",
    "top10_scores.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores['name'] = top10_scores['business_id'].apply(lambda business_id: yelp['name']\n",
    "                                                         [(yelp['business_id'] == business_id)].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_sentiment = {}\n",
    "for biz_id in bottom10['business_id'].tolist():\n",
    "    bottom10_sentiment[yelp.loc[yelp['business_id'] == biz_id, 'name'].iloc[0]] = sentiment[sentiment['business_id'] == biz_id].groupby(['business_id']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores = pd.DataFrame()\n",
    "for restaurant in bottom10_sentiment:\n",
    "    bottom10_scores = bottom10_scores.append(pd.DataFrame(bottom10_sentiment[restaurant]))\n",
    "bottom10_scores.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores['name'] = bottom10_scores['business_id'].apply(lambda business_id: yelp['name']\n",
    "                                                               [(yelp['business_id'] == business_id)].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom10_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_scores.to_csv('data/yelp_top_scores.csv', index=False)\n",
    "bottom10_scores.to_csv('data/yelp_bottom_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 10 Cuisine types (Mexican, American, Thai, etc) based on the number of restaurants and number of check ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = yelp[yelp['categories'].str.contains('Restaurants', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "restaurants['categories'] = restaurants['categories'].apply(lambda x: x.split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = restaurants.join(pd.get_dummies(pd.DataFrame(restaurants['categories'].tolist()).stack()).astype(int).sum(level=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [item for item in restaurants.columns.tolist() if item not in yelp.columns.tolist()]\n",
    "columns.remove('Restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food                                3607.0\n",
       "Nightlife                           2399.0\n",
       "Bars                                2313.0\n",
       "Sandwiches                          2166.0\n",
       "Pizza                               2139.0\n",
       "Fast Food                           2089.0\n",
       "American (Traditional)              2083.0\n",
       "Breakfast & Brunch                  1566.0\n",
       "Burgers                             1558.0\n",
       "Italian                             1384.0\n",
       "Mexican                             1335.0\n",
       "American (New)                      1308.0\n",
       "Chinese                             1265.0\n",
       "Coffee & Tea                         992.0\n",
       "Cafes                                955.0\n",
       "Chicken Wings                        809.0\n",
       "Japanese                             794.0\n",
       "Salad                                736.0\n",
       "Seafood                              714.0\n",
       "Event Planning & Services            655.0\n",
       "Sushi Bars                           641.0\n",
       "Canadian (New)                       614.0\n",
       "Delis                                591.0\n",
       "Mediterranean                        530.0\n",
       "Barbeque                             526.0\n",
       "Asian Fusion                         519.0\n",
       "Steakhouses                          517.0\n",
       "Specialty Food                       504.0\n",
       "Sports Bars                          490.0\n",
       "Bakeries                             459.0\n",
       "                                     ...  \n",
       "Siding                                 0.0\n",
       "Sicilian                               0.0\n",
       "Eastern European                       0.0\n",
       "Feng Shui                              0.0\n",
       "Farms                                  0.0\n",
       "Family Practice                        0.0\n",
       "Rest Stops                             0.0\n",
       "Eyebrow Services                       0.0\n",
       "Reunion                                0.0\n",
       "Event Photography                      0.0\n",
       "Roofing                                0.0\n",
       "Estate Planning Law                    0.0\n",
       "Estate Liquidation                     0.0\n",
       "Electricians                           0.0\n",
       "Sailing                                0.0\n",
       "Dry Cleaning & Laundry                 0.0\n",
       "Session Photography                    0.0\n",
       "Dry Cleaning                           0.0\n",
       "Drive-Thru Bars                        0.0\n",
       "Screen Printing                        0.0\n",
       "Screen Printing/T-Shirt Printing       0.0\n",
       "Security Services                      0.0\n",
       "Dog Walkers                            0.0\n",
       "Medical Spas                           0.0\n",
       "Divorce & Family Law                   0.0\n",
       "Senegalese                             0.0\n",
       "Distilleries                           0.0\n",
       "Septic Services                        0.0\n",
       "Serbo Croatian                         0.0\n",
       "& Probates                             0.0\n",
       "Length: 706, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_restaurants = restaurants[columns].sum(numeric_only=True).sort_values(ascending=False)\n",
    "num_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_dict ={}\n",
    "for item in columns:\n",
    "    cnt = restaurants[restaurants[item] == 1].groupby([item])['checkins'].sum()\n",
    "    if cnt.empty:\n",
    "        checkin_dict[item] = 0\n",
    "    else:\n",
    "        checkin_dict[item] = restaurants[restaurants[item] == 1].groupby([item])['checkins'].sum().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_dict = pd.Series(checkin_dict).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food\n",
      "Nightlife\n",
      "Bars\n",
      "Sandwiches\n",
      "Pizza\n",
      "Fast Food\n",
      "American (Traditional)\n",
      "Breakfast & Brunch\n",
      "Mexican\n",
      "Burgers\n",
      "Chinese\n",
      "Italian\n",
      "American (New)\n",
      "Coffee & Tea\n",
      "Chicken Wings\n",
      "Japanese\n",
      "Cafes\n",
      "Event Planning & Services\n",
      "Salad\n",
      "Thai\n",
      "Seafood\n",
      "Specialty Food\n",
      "Canadian (New)\n",
      "Sports Bars\n",
      "Sushi Bars\n",
      "Caterers\n",
      "Steakhouses\n",
      "Pubs\n",
      "Barbeque\n",
      "Delis\n",
      "Desserts\n",
      "Mediterranean\n",
      "Asian Fusion\n",
      "Bakeries\n",
      "Indian\n",
      "Beer\n",
      "Wine & Spirits\n",
      "Diners\n",
      "Buffets\n",
      "Korean\n",
      "Lounges\n",
      "Greek\n",
      "Wine Bars\n",
      "Cocktail Bars\n",
      "Vegetarian\n",
      "Middle Eastern\n",
      "Gluten-Free\n",
      "Vietnamese\n",
      "Soup\n",
      "French\n",
      "Ethnic Food\n",
      "Juice Bars & Smoothies\n",
      "Comfort Food\n",
      "Food Trucks\n",
      "Hot Dogs\n",
      "Tex-Mex\n",
      "Gastropubs\n",
      "Caribbean\n",
      "Arts & Entertainment\n",
      "Grocery\n",
      "Vegan\n",
      "Food Delivery Services\n",
      "Ice Cream & Frozen Yogurt\n",
      "Latin American\n",
      "Noodles\n",
      "Food Stands\n",
      "Chicken Shop\n",
      "Shopping\n",
      "Venues & Event Spaces\n",
      "Tapas Bars\n",
      "Irish\n",
      "Bagels\n",
      "Tapas/Small Plates\n",
      "Southern\n",
      "Halal\n",
      "Breweries\n",
      "Pakistani\n",
      "Hawaiian\n",
      "Ramen\n",
      "Creperies\n",
      "Music Venues\n",
      "Poutineries\n",
      "Hotels & Travel\n",
      "Fish & Chips\n",
      "Health Markets\n",
      "Party & Event Planning\n",
      "Dance Clubs\n",
      "Imported Food\n",
      "Cajun/Creole\n",
      "Local Flavor\n",
      "African\n",
      "Dim Sum\n",
      "Modern European\n",
      "Portuguese\n",
      "Cheesesteaks\n",
      "Beer Bar\n",
      "Active Life\n",
      "Hotels\n",
      "Irish Pub\n",
      "Tacos\n",
      "Karaoke\n",
      "German\n",
      "Polish\n",
      "Soul Food\n",
      "Taiwanese\n",
      "Street Vendors\n",
      "Donuts\n",
      "Chocolatiers & Shops\n",
      "Spanish\n",
      "Filipino\n",
      "Lebanese\n",
      "Kosher\n",
      "Fashion\n",
      "Food Court\n",
      "Peruvian\n",
      "Falafel\n",
      "Tea Rooms\n",
      "Gelato\n",
      "Persian/Iranian\n",
      "Brazilian\n",
      "Jazz & Blues\n",
      "Bubble Tea\n",
      "Men's Clothing\n",
      "British\n",
      "Ethiopian\n",
      "Dominican\n",
      "Cheese Shops\n",
      "Cupcakes\n",
      "Dive Bars\n",
      "Farmers Market\n",
      "Bowling\n",
      "Convenience Stores\n",
      "Poke\n",
      "Cigar Bars\n",
      "Hot Pot\n",
      "Seafood Markets\n",
      "Afghan\n",
      "Bistros\n",
      "Smokehouse\n",
      "Brewpubs\n",
      "Whiskey Bars\n",
      "Cantonese\n",
      "Bed & Breakfast\n",
      "Meat Shops\n",
      "Wraps\n",
      "Organic Stores\n",
      "Butcher\n",
      "Hungarian\n",
      "Delicatessen\n",
      "Salvadoran\n",
      "Home & Garden\n",
      "Adult Entertainment\n",
      "Malaysian\n",
      "Casinos\n",
      "Shaved Ice\n",
      "New Mexican Cuisine\n",
      "Festivals\n",
      "Szechuan\n",
      "Cafeteria\n",
      "Patisserie/Cake Shop\n",
      "Home Services\n",
      "Hookah Bars\n",
      "Coffee Roasteries\n",
      "Hakka\n",
      "Cambodian\n",
      "Flowers & Gifts\n",
      "Turkish\n",
      "Brasseries\n",
      "Candy Stores\n",
      "Beauty & Spas\n",
      "Kebab\n",
      "Arabian\n",
      "Hobby Shops\n",
      "Pasta Shops\n",
      "Wineries\n",
      "International Grocery\n",
      "Personal Chefs\n",
      "Internet Cafes\n",
      "Local Services\n",
      "Fondue\n",
      "Health & Medical\n",
      "Playgrounds\n",
      "Live/Raw Food\n",
      "Popcorn Shops\n",
      "Pub Food\n",
      "Puerto Rican\n",
      "Colombian\n",
      "Custom Cakes\n",
      "Music & Video\n",
      "Books\n",
      "Mags\n",
      "DJs\n",
      "Pool Halls\n",
      "Waffles\n",
      "Himalayan/Nepalese\n",
      "Education\n",
      "Arcades\n",
      "Belgian\n",
      "Fruits & Veggies\n",
      "Sporting Goods\n",
      "Sugar Shacks\n",
      "Cuban\n",
      "Golf\n",
      "Beer Gardens\n",
      "Newspapers & Magazines\n",
      "Performing Arts\n",
      "Hair Salons\n",
      "Day Spas\n",
      "Churches\n",
      "Religious Organizations\n",
      "Toy Stores\n",
      "Specialty Schools\n",
      "Automotive\n",
      "Appliances\n",
      "Kitchen & Bath\n",
      "Do-It-Yourself Food\n",
      "Transportation\n",
      "Dinner Theater\n",
      "Limos\n",
      "Appliances & Repair\n",
      "Egyptian\n",
      "Arts & Crafts\n",
      "Airport Lounges\n",
      "Teppanyaki\n",
      "Pan Asian\n",
      "Christmas Trees\n",
      "Nail Salons\n",
      "Hospitals\n",
      "Acai Bowls\n",
      "Eatertainment\n",
      "Gift Shops\n",
      "Art Galleries\n",
      "Moroccan\n",
      "International\n",
      "Florists\n",
      "Home Decor\n",
      "Real Estate\n",
      "Professional Services\n",
      "Discount Store\n",
      "Gay Bars\n",
      "Restaurant Supplies\n",
      "Metal Fabricators\n",
      "Wholesalers\n",
      "Art Schools\n",
      "Palatine\n",
      "Russian\n",
      "Dance Schools\n",
      "Preschools\n",
      "Social Clubs\n",
      "Shopping Centers\n",
      "Tanning\n",
      "South African\n",
      "Accessories\n",
      "Sri Lankan\n",
      "Donairs\n",
      "Mongolian\n",
      "Bike Rentals\n",
      "Champagne Bars\n",
      "Indonesian\n",
      "Public Services & Government\n",
      "Makeup Artists\n",
      "Olive Oil\n",
      "Resorts\n",
      "Fitness & Instruction\n",
      "Macarons\n",
      "Towing\n",
      "Beer Garden\n",
      "Massage\n",
      "Real Estate Services\n",
      "Argentine\n",
      "Hair Stylists\n",
      "Massage Therapy\n",
      "Gas Stations\n",
      "Ukrainian\n",
      "Property Management\n",
      "Real Estate Agents\n",
      "Haitian\n",
      "Department Stores\n",
      "Kids Activities\n",
      "Recreation Centers\n",
      "Coffee & Tea Supplies\n",
      "Cooking Schools\n",
      "Body Shops\n",
      "Financial Services\n",
      "Bavarian\n",
      "Club Crawl\n",
      "Shanghainese\n",
      "Bangladeshi\n",
      "Syrian\n",
      "Empanadas\n",
      "Themed Cafes\n",
      "Auto Repair\n",
      "Nutritionists\n",
      "Cooking Classes\n",
      "Grilling Equipment\n",
      "Venezuelan\n",
      "Wholesale Stores\n",
      "Singaporean\n",
      "Insurance\n",
      "Auto Glass Services\n",
      "Auto Insurance\n",
      "Auto Parts & Supplies\n",
      "Transmission Repair\n",
      "Oil Change Stations\n",
      "Windshield Installation & Repair\n",
      "Bike Repair/Maintenance\n",
      "Art Classes\n",
      "Izakaya\n",
      "Tuscan\n",
      "Tours\n",
      "Sports Wear\n",
      "Bikes\n",
      "Pretzels\n",
      "Amusement Parks\n",
      "Furniture Stores\n",
      "Stadiums & Arenas\n",
      "Golf Lessons\n",
      "Cosmetics & Beauty Supply\n",
      "Drugstores\n",
      "Piano Bars\n",
      "Colleges & Universities\n",
      "Community Service/Non-Profit\n",
      "Laser Tag\n",
      "Mattresses\n",
      "Beverage Store\n",
      "Comedy Clubs\n",
      "Outdoor Furniture Stores\n",
      "Czech\n",
      "Austrian\n",
      "Shared Office Spaces\n",
      "Pharmacy\n",
      "Landmarks & Historical Buildings\n",
      "Bookstores\n",
      "Women's Clothing\n",
      "Trinidadian\n",
      "Cards & Stationery\n",
      "Flea Markets\n",
      "Spray Tanning\n",
      "Eyelash Service\n",
      "Hair Removal\n",
      "Mini Golf\n",
      "Brazilian Jiu-jitsu\n",
      "Martial Arts\n",
      "Gyms\n",
      "Trainers\n",
      "Observatories\n",
      "Rotisserie Chicken\n",
      "Ethical Grocery\n",
      "Rock Climbing\n",
      "Speakeasies\n",
      "Hair Extensions\n",
      "Cinema\n",
      "Tiki Bars\n",
      "Country Dance Halls\n",
      "Strip Clubs\n",
      "Laotian\n",
      "Island Pub\n",
      "Nail Technicians\n",
      "Museums\n",
      "Boat Charters\n",
      "Travel Services\n",
      "Handyman\n",
      "Weight Loss Centers\n",
      "Bartending Schools\n",
      "Burmese\n",
      "Antiques\n",
      "Party Supplies\n",
      "Japanese Curry\n",
      "Airports\n",
      "Printing Services\n",
      "Czech/Slovakian\n",
      "Trophy Shops\n",
      "Outlet Stores\n",
      "Engraving\n",
      "Pets\n",
      "Wine Tours\n",
      "Vinyl Records\n",
      "Vitamins & Supplements\n",
      "Adult Education\n",
      "Cabaret\n",
      "Art Museums\n",
      "Skin Care\n",
      "Wedding Planning\n",
      "Post Offices\n",
      "Pet Stores\n",
      "Leisure Centers\n",
      "Couriers & Delivery Services\n",
      "Pita\n",
      "Wigs\n",
      "Apartments\n",
      "Pop-Up Restaurants\n",
      "Ticket Sales\n",
      "Waxing\n",
      "Hotel bar\n",
      "Health Retreats\n",
      "Reflexology\n",
      "Occupational Therapy\n",
      "Physical Therapy\n",
      "Acupuncture\n",
      "Plumbing\n",
      "Rehabilitation Center\n",
      "Tobacco Shops\n",
      "Used\n",
      "Vintage & Consignment\n",
      "Iberian\n",
      "Sugaring\n",
      "Comic Books\n",
      "Public Markets\n",
      "Yoga\n",
      "Meditation Centers\n",
      "Country Clubs\n",
      "Tabletop Games\n",
      "Hardware Stores\n",
      "Home Cleaning\n",
      "Pensions\n",
      "Pet Sitting\n",
      "Pet Services\n",
      "Race Tracks\n",
      "Swiss Food\n",
      "Doctors\n",
      "Supper Clubs\n",
      "Wine Tasting Room\n",
      "Shaved Snow\n",
      "Slovakian\n",
      "Banks & Credit Unions\n",
      "Paint & Sip\n",
      "Signature Cuisine\n",
      "Zoos\n",
      "Wedding Chapels\n",
      "Nicaraguan\n",
      "Musicians\n",
      "Team Building Activities\n",
      "Guamanian\n",
      "Pool & Hot Tub Service\n",
      "Beaches\n",
      "Local Fish Stores\n",
      "Taxis\n",
      "Airport Shuttles\n",
      "Sports Clubs\n",
      "Heating & Air Conditioning/HVAC\n",
      "Souvenir Shops\n",
      "Head Shops\n",
      "Investing\n",
      "Botanical Gardens\n",
      "Cultural Center\n",
      "Yelp Events\n",
      "Audio/Visual Equipment Rental\n",
      "Lighting Fixtures & Equipment\n",
      "Ice Delivery\n",
      "Furniture Rental\n",
      "Fur Clothing\n",
      "Pilates\n",
      "Furniture Repair\n",
      "Party Equipment Rentals\n",
      "Photo Booth Rentals\n",
      "Electronics\n",
      "Bridal\n",
      "Dentists\n",
      "Escape Games\n",
      "Boating\n",
      "Marinas\n",
      "Parks\n",
      "Bankruptcy Law\n",
      "Lawyers\n",
      "Contractors\n",
      "Videos & Video Game Rental\n",
      "Basque\n",
      "Chiropractors\n",
      "Tonkatsu\n",
      "Australian\n",
      "Emergency Medicine\n",
      "Traditional Norwegian\n",
      "Cardiologists\n",
      "Pediatricians\n",
      "Tempura\n",
      "Cheese Tasting Classes\n",
      "Foundation Repair\n",
      "Flooring\n",
      "Tasting Classes\n",
      "Masonry/Concrete\n",
      "Herbs & Spices\n",
      "Barbers\n",
      "Go Karts\n",
      "Batting Cages\n",
      "Hostels\n",
      "Mobile Phone Repair\n",
      "Dance Studios\n",
      "IT Services & Computer Repair\n",
      "Mauritius\n",
      "Tax Services\n",
      "Accountants\n",
      "Pop-up Shops\n",
      "Coffeeshops\n",
      "Kids Hair Salons\n",
      "Armenian\n",
      "Northern German\n",
      "Art Supplies\n",
      "Food Tours\n",
      "Animal Shelters\n",
      "Swimming Pools\n",
      "Vacation Rentals\n",
      "Horseback Riding\n",
      "Ethnic Grocery\n",
      "Air Duct Cleaning\n",
      "Landscaping\n",
      "Fire Protection Services\n",
      "Nurseries & Gardening\n",
      "Hot Tub & Pool\n",
      "Office Cleaning\n",
      "Gardeners\n",
      "Personal Shopping\n",
      "Mountain Biking\n",
      "Honey\n",
      "Shoe Stores\n",
      "Cannabis Clinics\n",
      "Leather Goods\n",
      "Libraries\n",
      "Glass & Mirrors\n",
      "Windows Installation\n",
      "Door Sales/Installation\n",
      "Water Stores\n",
      "Scandinavian\n",
      "Business Consulting\n",
      "Software Development\n",
      "Clowns\n",
      "Magicians\n",
      "Gun/Rifle Ranges\n",
      "Scottish\n",
      "Horse Racing\n",
      "Car Wash\n",
      "Septic Services\n",
      "Soccer\n",
      "Boat Repair\n",
      "Boat Dealers\n",
      "Serbo Croatian\n",
      "Building Supplies\n",
      "Roofing\n",
      "Sailing\n",
      "Senegalese\n",
      "Security Systems\n",
      "Beer Hall\n",
      "Soba\n",
      "Bingo Halls\n",
      "Skydiving\n",
      "Ski Resorts\n",
      "Screen Printing\n",
      "Skating Rinks\n",
      "Sicilian\n",
      "Screen Printing/T-Shirt Printing\n",
      "Session Photography\n",
      "Security Services\n",
      "Siding\n",
      "Signmaking\n",
      "General Dentistry\n",
      "Special Education\n",
      "Alternative Medicine\n",
      "Uzbek\n",
      "Aquariums\n",
      "Aquarium Services\n",
      "Vape Shops\n",
      "Vehicle Wraps\n",
      "Veterinarians\n",
      "Video Game Stores\n",
      "Virtual Reality Centers\n",
      "Amateur Sports Teams\n",
      "Airsoft\n",
      "Summer Camps\n",
      "Visitor Centers\n",
      "Airport Terminals\n",
      "Walking Tours\n",
      "Aircraft Repairs\n",
      "Water Heater Installation/Repair\n",
      "Advertising\n",
      "Web Design\n",
      "Wills\n",
      "Wine Tasting Classes\n",
      "Used Bookstore\n",
      "Unofficial Yelp Events\n",
      "University Housing\n",
      "Udon\n",
      "Supernatural Readings\n",
      "Bartenders\n",
      "Tai Chi\n",
      "Bar Crawl\n",
      "Tattoo\n",
      "Tax Law\n",
      "Baguettes\n",
      "Baby Gear & Furniture\n",
      "Auto Upholstery\n",
      "Teeth Whitening\n",
      "Tennis\n",
      "Reunion\n",
      "Thrift Stores\n",
      "Auto Detailing\n",
      "Auto Customization\n",
      "Tires\n",
      "Trampoline Parks\n",
      "Truck Rental\n",
      "Trusts\n",
      "Bulgarian\n",
      "Chilean\n",
      "Rest Stops\n",
      "Medical Centers\n",
      "Estate Liquidation\n",
      "Jewelry\n",
      "Electricians\n",
      "Keys & Locksmiths\n",
      "Knife Sharpening\n",
      "Eastern European\n",
      "Dry Cleaning & Laundry\n",
      "Dry Cleaning\n",
      "Kombucha\n",
      "Drive-Thru Bars\n",
      "Lakes\n",
      "Landscape Architects\n",
      "Dog Walkers\n",
      "Laser Hair Removal\n",
      "Laundromat\n",
      "Divorce & Family Law\n",
      "Laundry Services\n",
      "Distilleries\n",
      "Life Coach\n",
      "Mailbox Centers\n",
      "Day Camps\n",
      "Marketing\n",
      "Damage Restoration\n",
      "Estate Planning Law\n",
      "Interior Design\n",
      "Indoor Playcentre\n",
      "Home Health Care\n",
      "Game Meat\n",
      "Golf Equipment\n",
      "Furniture Reupholstery\n",
      "Funeral Services & Cemeteries\n",
      "Golf Equipment Shops\n",
      "Graphic Design\n",
      "Guest Houses\n",
      "Hainan\n",
      "Hiking\n",
      "Historical Tours\n",
      "Fishmonger\n",
      "Immigration Law\n",
      "Fishing\n",
      "Home Inspectors\n",
      "Fireplace Services\n",
      "Honduran\n",
      "Hong Kong Style Cafe\n",
      "Feng Shui\n",
      "Farms\n",
      "Family Practice\n",
      "Eyebrow Services\n",
      "Event Photography\n",
      "Mass Media\n",
      "Customized Merchandise\n",
      "Bus Tours\n",
      "Medical Spas\n",
      "Pawn Shops\n",
      "Personal Assistants\n",
      "Personal Injury Law\n",
      "Pet Adoption\n",
      "Pet Boarding\n",
      "Pet Groomers\n",
      "Check Cashing/Pay-day Loans\n",
      "Photographers\n",
      "Pick Your Own Farms\n",
      "Piercing\n",
      "Car Window Tinting\n",
      "Car Share Services\n",
      "Car Rental\n",
      "Car Dealers\n",
      "Pool & Billiards\n",
      "Campgrounds\n",
      "Print Media\n",
      "Psychics\n",
      "Public Transportation\n",
      "Pumpkin Patches\n",
      "RV Parks\n",
      "CSA\n",
      "RV Repair\n",
      "Churros\n",
      "Cideries\n",
      "Party Bus Rentals\n",
      "Motorcycle Repair\n",
      "Currency Exchange\n",
      "Medical Transportation\n",
      "Milkshake Bars\n",
      "Minho\n",
      "Mobile Phones\n",
      "Mortgage Brokers\n",
      "Counseling & Mental Health\n",
      "Mosques\n",
      "Cosmetic Surgeons\n",
      "Cosmetic Dentists\n",
      "Conveyor Belt Sushi\n",
      "Climbing\n",
      "Music & DVDs\n",
      "Computers\n",
      "Community Centers\n",
      "Commercial Truck Repair\n",
      "Opera & Ballet\n",
      "Orthodontists\n",
      "Paint-Your-Own Pottery\n",
      "Parenting Classes\n",
      "Parking\n",
      "Clothing Rental\n",
      "& Probates\n"
     ]
    }
   ],
   "source": [
    "for item in checkin_dict.keys():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(checkin_dict).to_csv('data/yelp_cuisine_checkin.csv', index=False)\n",
    "pd.DataFrame(num_restaurants).to_csv('data/yelp_cuisine_restaurants.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most popular keywords or adjectives that reviewers use for the above list of cuisines (calculated in step 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cuisine_list = ['American (Traditional)', 'Mexican', 'Chinese', 'Italian', 'American (New)',\n",
    "               'Japanese', 'Thai', 'Mediterranean', 'Asian Fusion', 'Indian', 'Korean',\n",
    "                'Greek', 'Mddle Eastern', 'Vietnamese', 'French', 'Tex-Mex', 'Caribbean']\n",
    "cuisines = pd.DataFrame()\n",
    "for cuisine in cuisine_list:\n",
    "    businesses = yelp[yelp['categories'].str.contains(cuisine, na=False)]['business_id'].tolist()\n",
    "    temp = review[review['business_id'].isin(businesses)]\n",
    "    temp['cuisine'] = cuisine\n",
    "    cuisines = pd.concat([cuisines, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "nlp.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American (Traditional)\n",
      "chunk 1 of 1\n",
      "Mexican\n",
      "chunk 1 of 34\n",
      "chunk 2 of 34\n",
      "chunk 3 of 34\n",
      "chunk 4 of 34\n",
      "chunk 5 of 34\n",
      "chunk 6 of 34\n",
      "chunk 7 of 34\n",
      "chunk 8 of 34\n",
      "chunk 9 of 34\n",
      "chunk 10 of 34\n",
      "chunk 11 of 34\n",
      "chunk 12 of 34\n",
      "chunk 13 of 34\n",
      "chunk 14 of 34\n",
      "chunk 15 of 34\n",
      "chunk 16 of 34\n",
      "chunk 17 of 34\n",
      "chunk 18 of 34\n",
      "chunk 19 of 34\n",
      "chunk 20 of 34\n",
      "chunk 21 of 34\n",
      "chunk 22 of 34\n",
      "chunk 23 of 34\n",
      "chunk 24 of 34\n",
      "chunk 25 of 34\n",
      "chunk 26 of 34\n",
      "chunk 27 of 34\n",
      "chunk 28 of 34\n",
      "chunk 29 of 34\n",
      "chunk 30 of 34\n",
      "chunk 31 of 34\n",
      "chunk 32 of 34\n",
      "chunk 33 of 34\n",
      "chunk 34 of 34\n",
      "Chinese\n",
      "chunk 1 of 24\n",
      "chunk 2 of 24\n",
      "chunk 3 of 24\n",
      "chunk 4 of 24\n",
      "chunk 5 of 24\n",
      "chunk 6 of 24\n",
      "chunk 7 of 24\n",
      "chunk 8 of 24\n",
      "chunk 9 of 24\n",
      "chunk 10 of 24\n",
      "chunk 11 of 24\n",
      "chunk 12 of 24\n",
      "chunk 13 of 24\n",
      "chunk 14 of 24\n",
      "chunk 15 of 24\n",
      "chunk 16 of 24\n",
      "chunk 17 of 24\n",
      "chunk 18 of 24\n",
      "chunk 19 of 24\n",
      "chunk 20 of 24\n",
      "chunk 21 of 24\n",
      "chunk 22 of 24\n",
      "chunk 23 of 24\n",
      "chunk 24 of 24\n",
      "Italian\n",
      "chunk 1 of 33\n",
      "chunk 2 of 33\n",
      "chunk 3 of 33\n",
      "chunk 4 of 33\n",
      "chunk 5 of 33\n",
      "chunk 6 of 33\n",
      "chunk 7 of 33\n",
      "chunk 8 of 33\n",
      "chunk 9 of 33\n",
      "chunk 10 of 33\n",
      "chunk 11 of 33\n",
      "chunk 12 of 33\n",
      "chunk 13 of 33\n",
      "chunk 14 of 33\n",
      "chunk 15 of 33\n",
      "chunk 16 of 33\n",
      "chunk 17 of 33\n",
      "chunk 18 of 33\n",
      "chunk 19 of 33\n",
      "chunk 20 of 33\n",
      "chunk 21 of 33\n",
      "chunk 22 of 33\n",
      "chunk 23 of 33\n",
      "chunk 24 of 33\n",
      "chunk 25 of 33\n",
      "chunk 26 of 33\n",
      "chunk 27 of 33\n",
      "chunk 28 of 33\n",
      "chunk 29 of 33\n",
      "chunk 30 of 33\n",
      "chunk 31 of 33\n",
      "chunk 32 of 33\n",
      "chunk 33 of 33\n",
      "American (New)\n",
      "chunk 1 of 1\n",
      "Japanese\n",
      "chunk 1 of 30\n",
      "chunk 2 of 30\n",
      "chunk 3 of 30\n",
      "chunk 4 of 30\n",
      "chunk 5 of 30\n",
      "chunk 6 of 30\n",
      "chunk 7 of 30\n",
      "chunk 8 of 30\n",
      "chunk 9 of 30\n",
      "chunk 10 of 30\n",
      "chunk 11 of 30\n",
      "chunk 12 of 30\n",
      "chunk 13 of 30\n",
      "chunk 14 of 30\n",
      "chunk 15 of 30\n",
      "chunk 16 of 30\n",
      "chunk 17 of 30\n",
      "chunk 18 of 30\n",
      "chunk 19 of 30\n",
      "chunk 20 of 30\n",
      "chunk 21 of 30\n",
      "chunk 22 of 30\n",
      "chunk 23 of 30\n",
      "chunk 24 of 30\n",
      "chunk 25 of 30\n",
      "chunk 26 of 30\n",
      "chunk 27 of 30\n",
      "chunk 28 of 30\n",
      "chunk 29 of 30\n",
      "chunk 30 of 30\n",
      "Thai\n",
      "chunk 1 of 11\n",
      "chunk 2 of 11\n",
      "chunk 3 of 11\n",
      "chunk 4 of 11\n",
      "chunk 5 of 11\n",
      "chunk 6 of 11\n",
      "chunk 7 of 11\n",
      "chunk 8 of 11\n",
      "chunk 9 of 11\n",
      "chunk 10 of 11\n",
      "chunk 11 of 11\n",
      "Mediterranean\n",
      "chunk 1 of 12\n",
      "chunk 2 of 12\n",
      "chunk 3 of 12\n",
      "chunk 4 of 12\n",
      "chunk 5 of 12\n",
      "chunk 6 of 12\n",
      "chunk 7 of 12\n",
      "chunk 8 of 12\n",
      "chunk 9 of 12\n",
      "chunk 10 of 12\n",
      "chunk 11 of 12\n",
      "chunk 12 of 12\n",
      "Asian Fusion\n",
      "chunk 1 of 23\n",
      "chunk 2 of 23\n",
      "chunk 3 of 23\n",
      "chunk 4 of 23\n",
      "chunk 5 of 23\n",
      "chunk 6 of 23\n",
      "chunk 7 of 23\n",
      "chunk 8 of 23\n",
      "chunk 9 of 23\n",
      "chunk 10 of 23\n",
      "chunk 11 of 23\n",
      "chunk 12 of 23\n",
      "chunk 13 of 23\n",
      "chunk 14 of 23\n",
      "chunk 15 of 23\n",
      "chunk 16 of 23\n",
      "chunk 17 of 23\n",
      "chunk 18 of 23\n",
      "chunk 19 of 23\n",
      "chunk 20 of 23\n",
      "chunk 21 of 23\n",
      "chunk 22 of 23\n",
      "chunk 23 of 23\n",
      "Indian\n",
      "chunk 1 of 7\n",
      "chunk 2 of 7\n",
      "chunk 3 of 7\n",
      "chunk 4 of 7\n",
      "chunk 5 of 7\n",
      "chunk 6 of 7\n",
      "chunk 7 of 7\n",
      "Korean\n",
      "chunk 1 of 11\n",
      "chunk 2 of 11\n",
      "chunk 3 of 11\n",
      "chunk 4 of 11\n",
      "chunk 5 of 11\n",
      "chunk 6 of 11\n",
      "chunk 7 of 11\n",
      "chunk 8 of 11\n",
      "chunk 9 of 11\n",
      "chunk 10 of 11\n",
      "chunk 11 of 11\n",
      "Greek\n",
      "chunk 1 of 5\n",
      "chunk 2 of 5\n",
      "chunk 3 of 5\n",
      "chunk 4 of 5\n",
      "chunk 5 of 5\n",
      "Mddle Eastern\n",
      "chunk 1 of 1\n",
      "Vietnamese\n",
      "chunk 1 of 8\n",
      "chunk 2 of 8\n",
      "chunk 3 of 8\n",
      "chunk 4 of 8\n",
      "chunk 5 of 8\n",
      "chunk 6 of 8\n",
      "chunk 7 of 8\n",
      "chunk 8 of 8\n",
      "French\n",
      "chunk 1 of 9\n",
      "chunk 2 of 9\n",
      "chunk 3 of 9\n",
      "chunk 4 of 9\n",
      "chunk 5 of 9\n",
      "chunk 6 of 9\n",
      "chunk 7 of 9\n",
      "chunk 8 of 9\n",
      "chunk 9 of 9\n",
      "Tex-Mex\n",
      "chunk 1 of 5\n",
      "chunk 2 of 5\n",
      "chunk 3 of 5\n",
      "chunk 4 of 5\n",
      "chunk 5 of 5\n",
      "Caribbean\n",
      "chunk 1 of 3\n",
      "chunk 2 of 3\n",
      "chunk 3 of 3\n"
     ]
    }
   ],
   "source": [
    "cuisine_docs = {}\n",
    "\n",
    "for cuisine in cuisine_list:\n",
    "    print()\n",
    "    print(cuisine)\n",
    "    text = cuisines[cuisines['cuisine'] == cuisine]['text'].str.cat(sep=' ')\n",
    "    chunk_size = 1000000\n",
    "    num_chunks = len(text) // chunk_size + 1\n",
    "    \n",
    "    words = []\n",
    "    adj = []\n",
    "    \n",
    "    for chunk in range(num_chunks):\n",
    "        print('  chunk', chunk + 1, 'of', num_chunks)\n",
    "        chunk_start = chunk_size * (chunk - 1)\n",
    "        chunk_end = chunk_size * chunk\n",
    "        chunk_text = text[chunk_start: chunk_end]\n",
    "    \n",
    "        doc = nlp(chunk_text)\n",
    "        # all tokens that arent stop words or punctuations\n",
    "        words.extend([token.text for token in doc if\n",
    "                      token.is_stop !=True and token.is_punct != True])\n",
    "\n",
    "        # adjective tokens that arent stop words or punctuations\n",
    "        adj.extend([token.text for token in doc if\n",
    "                    token.is_stop != True and\n",
    "                    token.is_punct != True and token.pos_ == \"ADJ\"])\n",
    "\n",
    "    # 200 most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(200)\n",
    "\n",
    "    # five most common adjective tokens\n",
    "    adj_freq = Counter(adj)\n",
    "    common_adj = adj_freq.most_common(200)\n",
    "    \n",
    "    cuisine_docs[cuisine] = {'words': words,\n",
    "                               'adj': adj,\n",
    "                               'common_words': common_words,\n",
    "                               'common_adj': common_adj}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_df = pd.DataFrame()\n",
    "\n",
    "for cuisine in cuisine_docs.keys():\n",
    "    temp = pd.DataFrame({'words': [cuisine_docs[cuisine]['words']],\n",
    "                         'adj': [cuisine_docs[cuisine]['adj']],\n",
    "                         'common_words': [cuisine_docs[cuisine]['common_words']],\n",
    "                         'common_adj': [cuisine_docs[cuisine]['common_adj']]})\n",
    "    temp['cuisine'] = cuisine\n",
    "    cuisine_df = pd.concat([cuisine_df, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>adj</th>\n",
       "      <th>common_words</th>\n",
       "      <th>common_adj</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>American (Traditional)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Finally, After, trying, Mexican, restaurants,...</td>\n",
       "      <td>[Mexican, authentic, Mexican, AMAZING, Fresh, ...</td>\n",
       "      <td>[(I, 170290), ( , 66807), (The, 64525), (food,...</td>\n",
       "      <td>[(good, 35021), (great, 23566), (Mexican, 1490...</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, spicy, wonton, favorite, We, ordered, ro...</td>\n",
       "      <td>[spicy, favorite, good, better, salty, okay, G...</td>\n",
       "      <td>[(I, 111244), (The, 45001), ( , 42063), (food,...</td>\n",
       "      <td>[(good, 24698), (great, 11356), (Chinese, 1116...</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Had, ruby, salad, carpaccio, salmon, ravioli,...</td>\n",
       "      <td>[amazing, amazing, bad, quick, cold, hot, ok, ...</td>\n",
       "      <td>[(I, 147247), ( , 71353), (The, 62021), (food,...</td>\n",
       "      <td>[(good, 30445), (great, 23426), (My, 12007), (...</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>American (New)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Sansotei, serves, notch, ramen, They, reserva...</td>\n",
       "      <td>[half, normal, favorite, Our, spicy, exception...</td>\n",
       "      <td>[(I, 142615), (The, 58878), ( , 45463), (\\n\\n,...</td>\n",
       "      <td>[(good, 30031), (great, 18401), (fresh, 9945),...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[I, REALLY, wanted, like, place, A, lot, frien...</td>\n",
       "      <td>[amazing, nice, great, busy, amazing, yellow, ...</td>\n",
       "      <td>[(I, 52779), (The, 20374), (food, 18759), ( , ...</td>\n",
       "      <td>[(good, 11000), (great, 6321), (delicious, 393...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[This, far, favorite, Mediterranean, restauran...</td>\n",
       "      <td>[favorite, fresh, delightful, amazing, large, ...</td>\n",
       "      <td>[(I, 56064), (The, 23747), ( , 21145), (food, ...</td>\n",
       "      <td>[(good, 10908), (great, 7978), (delicious, 523...</td>\n",
       "      <td>Mediterranean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[The, spicy, wonton, favorite, We, ordered, ro...</td>\n",
       "      <td>[spicy, favorite, good, better, salty, okay, g...</td>\n",
       "      <td>[(I, 109313), (The, 44566), ( , 38044), (\\n\\n,...</td>\n",
       "      <td>[(good, 23127), (great, 13914), (delicious, 72...</td>\n",
       "      <td>Asian Fusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Non, existened, service,  , The, waiter, grea...</td>\n",
       "      <td>[male, different, Its, dreadful, worse, fast, ...</td>\n",
       "      <td>[(I, 28206), (food, 13771), (The, 12647), ( , ...</td>\n",
       "      <td>[(good, 6598), (Indian, 6398), (great, 3456), ...</td>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Excellent, food, service, friendly, servers, ...</td>\n",
       "      <td>[Excellent, friendly, soft, best, attentive, q...</td>\n",
       "      <td>[(I, 45482), (The, 20621), (\\n\\n, 16445), ( , ...</td>\n",
       "      <td>[(good, 10660), (Korean, 8026), (great, 5954),...</td>\n",
       "      <td>Korean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Not, happy, meal, I, got, Mama, Mia, gyro, me...</td>\n",
       "      <td>[happy, gyro, small, small, heavy, odd, Greek,...</td>\n",
       "      <td>[(I, 21204), (The, 8716), ( , 8602), (food, 76...</td>\n",
       "      <td>[(good, 4265), (great, 2973), (Greek, 2549), (...</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Mddle Eastern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Food, good,  , Prices, Jen, 's, street, meat,...</td>\n",
       "      <td>[good, bigger, My, favourite, homemade, outsta...</td>\n",
       "      <td>[(I, 38374), (The, 14488), ( , 11719), (\\n\\n, ...</td>\n",
       "      <td>[(good, 8228), (great, 4039), (Vietnamese, 328...</td>\n",
       "      <td>Vietnamese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Loved, fried, goat, cheese, tomato, sauce, do...</td>\n",
       "      <td>[nice, excellent, new, streaky, warm, cool, wa...</td>\n",
       "      <td>[(I, 33768), (The, 16550), ( , 15027), (\\n\\n, ...</td>\n",
       "      <td>[(good, 6594), (great, 4937), (delicious, 3310...</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Let, start, saying, I, love, Taco, Bell, wors...</td>\n",
       "      <td>[worst, wrong, Last, spicy, burrito, sour, awf...</td>\n",
       "      <td>[(I, 20756), ( , 8051), (The, 7314), (food, 59...</td>\n",
       "      <td>[(good, 3919), (great, 2762), (My, 1413), (nic...</td>\n",
       "      <td>Tex-Mex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[First, let, service, fantastic, Jason, Elsie,...</td>\n",
       "      <td>[fantastic, multiple, Fabulous, closer, good, ...</td>\n",
       "      <td>[(I, 11027), (The, 4384), ( , 3620), (food, 35...</td>\n",
       "      <td>[(good, 2064), (great, 1191), (delicious, 842)...</td>\n",
       "      <td>Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                words  \\\n",
       "0                                                  []   \n",
       "1   [Finally, After, trying, Mexican, restaurants,...   \n",
       "2   [The, spicy, wonton, favorite, We, ordered, ro...   \n",
       "3   [Had, ruby, salad, carpaccio, salmon, ravioli,...   \n",
       "4                                                  []   \n",
       "5   [Sansotei, serves, notch, ramen, They, reserva...   \n",
       "6   [I, REALLY, wanted, like, place, A, lot, frien...   \n",
       "7   [This, far, favorite, Mediterranean, restauran...   \n",
       "8   [The, spicy, wonton, favorite, We, ordered, ro...   \n",
       "9   [Non, existened, service,  , The, waiter, grea...   \n",
       "10  [Excellent, food, service, friendly, servers, ...   \n",
       "11  [Not, happy, meal, I, got, Mama, Mia, gyro, me...   \n",
       "12                                                 []   \n",
       "13  [Food, good,  , Prices, Jen, 's, street, meat,...   \n",
       "14  [Loved, fried, goat, cheese, tomato, sauce, do...   \n",
       "15  [Let, start, saying, I, love, Taco, Bell, wors...   \n",
       "16  [First, let, service, fantastic, Jason, Elsie,...   \n",
       "\n",
       "                                                  adj  \\\n",
       "0                                                  []   \n",
       "1   [Mexican, authentic, Mexican, AMAZING, Fresh, ...   \n",
       "2   [spicy, favorite, good, better, salty, okay, G...   \n",
       "3   [amazing, amazing, bad, quick, cold, hot, ok, ...   \n",
       "4                                                  []   \n",
       "5   [half, normal, favorite, Our, spicy, exception...   \n",
       "6   [amazing, nice, great, busy, amazing, yellow, ...   \n",
       "7   [favorite, fresh, delightful, amazing, large, ...   \n",
       "8   [spicy, favorite, good, better, salty, okay, g...   \n",
       "9   [male, different, Its, dreadful, worse, fast, ...   \n",
       "10  [Excellent, friendly, soft, best, attentive, q...   \n",
       "11  [happy, gyro, small, small, heavy, odd, Greek,...   \n",
       "12                                                 []   \n",
       "13  [good, bigger, My, favourite, homemade, outsta...   \n",
       "14  [nice, excellent, new, streaky, warm, cool, wa...   \n",
       "15  [worst, wrong, Last, spicy, burrito, sour, awf...   \n",
       "16  [fantastic, multiple, Fabulous, closer, good, ...   \n",
       "\n",
       "                                         common_words  \\\n",
       "0                                                  []   \n",
       "1   [(I, 170290), ( , 66807), (The, 64525), (food,...   \n",
       "2   [(I, 111244), (The, 45001), ( , 42063), (food,...   \n",
       "3   [(I, 147247), ( , 71353), (The, 62021), (food,...   \n",
       "4                                                  []   \n",
       "5   [(I, 142615), (The, 58878), ( , 45463), (\\n\\n,...   \n",
       "6   [(I, 52779), (The, 20374), (food, 18759), ( , ...   \n",
       "7   [(I, 56064), (The, 23747), ( , 21145), (food, ...   \n",
       "8   [(I, 109313), (The, 44566), ( , 38044), (\\n\\n,...   \n",
       "9   [(I, 28206), (food, 13771), (The, 12647), ( , ...   \n",
       "10  [(I, 45482), (The, 20621), (\\n\\n, 16445), ( , ...   \n",
       "11  [(I, 21204), (The, 8716), ( , 8602), (food, 76...   \n",
       "12                                                 []   \n",
       "13  [(I, 38374), (The, 14488), ( , 11719), (\\n\\n, ...   \n",
       "14  [(I, 33768), (The, 16550), ( , 15027), (\\n\\n, ...   \n",
       "15  [(I, 20756), ( , 8051), (The, 7314), (food, 59...   \n",
       "16  [(I, 11027), (The, 4384), ( , 3620), (food, 35...   \n",
       "\n",
       "                                           common_adj                 cuisine  \n",
       "0                                                  []  American (Traditional)  \n",
       "1   [(good, 35021), (great, 23566), (Mexican, 1490...                 Mexican  \n",
       "2   [(good, 24698), (great, 11356), (Chinese, 1116...                 Chinese  \n",
       "3   [(good, 30445), (great, 23426), (My, 12007), (...                 Italian  \n",
       "4                                                  []          American (New)  \n",
       "5   [(good, 30031), (great, 18401), (fresh, 9945),...                Japanese  \n",
       "6   [(good, 11000), (great, 6321), (delicious, 393...                    Thai  \n",
       "7   [(good, 10908), (great, 7978), (delicious, 523...           Mediterranean  \n",
       "8   [(good, 23127), (great, 13914), (delicious, 72...            Asian Fusion  \n",
       "9   [(good, 6598), (Indian, 6398), (great, 3456), ...                  Indian  \n",
       "10  [(good, 10660), (Korean, 8026), (great, 5954),...                  Korean  \n",
       "11  [(good, 4265), (great, 2973), (Greek, 2549), (...                   Greek  \n",
       "12                                                 []           Mddle Eastern  \n",
       "13  [(good, 8228), (great, 4039), (Vietnamese, 328...              Vietnamese  \n",
       "14  [(good, 6594), (great, 4937), (delicious, 3310...                  French  \n",
       "15  [(good, 3919), (great, 2762), (My, 1413), (nic...                 Tex-Mex  \n",
       "16  [(good, 2064), (great, 1191), (delicious, 842)...               Caribbean  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_df.to_csv('data/yelp_cuisine_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines_sample = cuisines\n",
    "# cuisines_sample = cuisines.sample(frac=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_docs = {}\n",
    "for cuisine in cuisine_list:\n",
    "    cuisine_docs[cuisine] = cuisines_sample[cuisines['cuisine'] == cuisines_sample]['text'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "for cuisine in cuisine_list:\n",
    "    doc = nlp(cuisine_docs[cuisine])\n",
    "    # all tokens that arent stop words or punctuations\n",
    "    words = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "    # noun tokens that arent stop words or punctuations\n",
    "    adj = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"ADJ\"]\n",
    "\n",
    "    # five most common tokens\n",
    "    word_freq = Counter(words)\n",
    "    common_words = word_freq.most_common(5)\n",
    "\n",
    "    # five most common noun tokens\n",
    "    noun_freq = Counter(nouns)\n",
    "    common_nouns = noun_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(cuisine_docs['Mexican'])\n",
    "# all tokens that arent stop words or punctuations\n",
    "words = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True]\n",
    "\n",
    "# noun tokens that arent stop words or punctuations\n",
    "nouns = [token.text for token in self.doc if token.is_stop != True and token.is_punct != True and token.pos_ == \"NOUN\"]\n",
    "\n",
    "# five most common tokens\n",
    "word_freq = Counter(words)\n",
    "common_words = word_freq.most_common(5)\n",
    "\n",
    "# five most common noun tokens\n",
    "noun_freq = Counter(nouns)\n",
    "common_nouns = noun_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cuisine in cuisine_list:\n",
    "    print(cuisine, len(cuisine_docs[cuisine]) / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy = pd.read_csv('data/chicago-divvy-bicycle-sharing-data/data_raw.csv', parse_dates=['starttime', 'stoptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy = divvy[divvy['starttime'].dt.year == 2017].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divvy.to_csv('data/divvy_2017_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy = pd.read_csv('data/divvy_2017_kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Top 5 stations with the most starts (showing # of starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_starts = divvy.groupby(['from_station_name'])['from_station_name'].count().sort_values(ascending=False)\n",
    "station_starts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = station_starts.head(5).plot(kind='bar', figsize=(15, 10), title='Top 5 Stations with Most Starts')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .15, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_coord = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = Basemap(width=10000000,height=6000000,projection='lcc',\n",
    "            resolution=None,lat_1=45.,lat_2=55,lat_0=50,lon_0=-107.)\n",
    "plt.figure(figsize=(19,20))\n",
    "map.bluemarble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in station_starts[5]:\n",
    "        loc = geolocator.geocode(city)\n",
    "        if not loc:\n",
    "            print(\"Could not locate {}\".format(city))\n",
    "            continue\n",
    "        x, y = map(loc.longitude, loc.latitude)\n",
    "        map.plot(x,y,marker='o',color='Red',markersize=int(math.sqrt(count))*scale)\n",
    "        plt.annotate(city, xy = (x,y), xytext=(-20,20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Trip duration by user type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_duration = divvy.groupby(['usertype'])['tripduration'].mean().sort_values(ascending=False)\n",
    "trip_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = divvy.boxplot(column='tripduration', by='usertype', figsize=(15,10), showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Most popular trips based on start station and stop station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_stations'] = divvy['from_station_name'] + ' TO ' + divvy['to_station_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_stations = divvy.groupby(['trip_stations'])['trip_stations'].count().sort_values(ascending=False)\n",
    "trip_stations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = trip_stations.head(10).plot(kind='bar', figsize=(15, 10), title='Top 10 Most Popular Trips')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005 + .05, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dict = {'path': list(trip_stations.index), 'frequency': list(trip_stations.values)}\n",
    "trip_dict['origin'] = [x.split(' TO ')[0] for x in trip_dict['path']]\n",
    "trip_dict['destination'] = [x.split(' TO ')[1] for x in trip_dict['path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "trips = defaultdict(list)\n",
    "\n",
    "for idx in range(len(trip_dict['path'])):\n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['origin-destination'].append('origin')\n",
    "    trips['station'].append(trip_dict['origin'][idx])\n",
    "    \n",
    "    trips['path'].append(trip_dict['path'][idx])\n",
    "    trips['origin-destination'].append('destination')\n",
    "    trips['station'].append(trip_dict['destination'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_gps = (divvy[divvy['from_station_name'].duplicated()]\n",
    "                [['from_station_name', 'latitude_start', 'longitude_start']].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = pd.DataFrame(trips).merge(stations_gps, how='left', left_on='station', right_on='from_station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.to_csv('data/trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Rider performance by Gender and Age based on avg trip distance (station to station), median speed (distance traveled / trip duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply geodesic distance by 1.25. Routes follow roads but the calculated route is direct (geodesic). A route straight down a road would be the same as the direct route; a route diagnoal to roads would be multiplied by 1.414 (thanks, Pythagoras!); assuming routes are evenly split between diagonal and direct, with some wiggle room, I'm splitting the difference at 1.25.\n",
    "\n",
    "I looked at using the Google Maps api to calculate the actual, along-the-road distance, but they've removed the free api key option. I also looked at Bing Maps, but it's rate limited and I have more than 98,000 routes in this dataset (and once I saw how big that number was, I realized that using api calls would take more than a few days!). So I opted for this *x1.25* method which is less accurate but far quicker and cheaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(row):\n",
    "    return (1.25 * (geopy.distance.distance((row['latitude_start'], row['longitude_start']),\n",
    "                                            (row['latitude_end'], row['longitude_end'])).m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['trip_distance'] = divvy.apply(find_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy['speed'] = divvy['trip_distance'] / divvy['tripduration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divvy[['starttime', 'stoptime', 'tripduration', 'latitude_start', 'longitude_start', 'latitude_end', 'longitude_end', 'trip_distance', 'speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
